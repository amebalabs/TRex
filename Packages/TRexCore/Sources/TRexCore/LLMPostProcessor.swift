import Foundation
import OSLog
import TRexLLM

/// Post-processes OCR text using LLM
public class LLMPostProcessor {
    private let logger = Logger(subsystem: "com.ameba.TRex", category: "LLMPostProcessor")
    private var provider: LLMProvider?
    private var config: LLMConfiguration
    private let networkChecker: NetworkChecker

    public init(config: LLMConfiguration) {
        self.config = config
        self.networkChecker = NetworkChecker()

        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ”§ INITIALIZING LLM POST-PROCESSOR")
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ“‹ Configuration:")
        logger.info("  â†’ Provider: \(config.postProcessProvider.rawValue)")
        logger.info("  â†’ Model: \(config.postProcessModel)")
        logger.info("  â†’ Has API key: \(config.resolvePostProcessAPIKey() != nil)")
        logger.info("  â†’ Has endpoint: \(config.postProcessCustomEndpoint?.isEmpty == false)")
        logger.info("  â†’ Prompt: \(config.postProcessPrompt.isEmpty ? "(empty)" : config.postProcessPrompt.prefix(50).description + "...")")

        // Create unified provider
        do {
            self.provider = try UnifiedLanguageModelProvider(
                providerType: config.postProcessProvider,
                apiKey: config.resolvePostProcessAPIKey(),
                endpoint: config.postProcessCustomEndpoint,
                modelName: config.postProcessModel
            )
            logger.info("âœ… LLM post-processor initialized successfully")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        } catch {
            logger.error("âŒ FAILED TO INITIALIZE POST-PROCESSOR")
            logger.error("  â†’ Error: \(error.localizedDescription)")
            logger.error("  â†’ Type: \(type(of: error))")
            logger.warning("âš ï¸ Post-processing will not be available")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            self.provider = nil
        }
    }

    /// Process OCR text with LLM
    /// - Parameters:
    ///   - text: The OCR text to process
    ///   - prompt: Optional custom prompt (uses default if nil)
    ///   - metadata: Optional OCR metadata context to help LLM understand the source
    /// - Returns: Processed text
    public func process(_ text: String, prompt: String? = nil, metadata: String? = nil) async throws -> String {
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ¤– LLM POST-PROCESSING STARTED")
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

        logger.info("ğŸ“‹ Configuration:")
        logger.info("  â†’ Provider: \(self.config.postProcessProvider.rawValue)")
        logger.info("  â†’ Model: \(self.config.postProcessModel)")
        logger.info("  â†’ Has custom endpoint: \(self.config.postProcessCustomEndpoint?.isEmpty == false)")

        // Check if provider is available
        guard let provider = provider else {
            logger.error("âŒ FAILURE: LLM provider not available")
            logger.error("  â†’ Likely cause: Missing or invalid API key")
            logger.error("  â†’ Check Settings > LLM > Post-Processing section")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            throw LLMError.invalidAPIKey
        }
        logger.info("âœ… Provider initialized")

        // Check if text is empty
        guard !text.isEmpty else {
            logger.warning("âš ï¸ Empty text provided, skipping post-processing")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            return text
        }
        logger.info("ğŸ“ Input text: \(text.count) characters")
        logger.debug("  â†’ Preview: \(text.prefix(100))...")

        if let metadata = metadata {
            logger.info("ğŸ“Š OCR Metadata: \(metadata)")
        } else {
            logger.debug("  â†’ No OCR metadata provided")
        }

        // Check network connectivity
        let networkAvailable = networkChecker.isNetworkAvailable()
        logger.info("ğŸŒ Network check: \(networkAvailable ? "âœ… Available" : "âŒ Unavailable")")
        guard networkAvailable else {
            logger.error("âŒ FAILURE: Network unavailable")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            throw LLMError.networkUnavailable
        }

        // Check provider connectivity
        logger.info("ğŸ”Œ Checking provider connectivity...")
        let canConnect = await provider.checkConnectivity()
        logger.info("  â†’ Result: \(canConnect ? "âœ… Connected" : "âŒ Cannot connect")")
        guard canConnect else {
            logger.error("âŒ FAILURE: Cannot connect to LLM provider")
            logger.error("  â†’ Check API key and endpoint configuration")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            throw LLMError.networkUnavailable
        }

        do {
            var promptToUse = prompt ?? config.postProcessPrompt

            // Prepend OCR metadata context if available
            if let metadata = metadata {
                let contextPrompt = "OCR Context: \(metadata)\n\n"
                promptToUse = promptToUse.isEmpty ? contextPrompt : contextPrompt + promptToUse
            }

            logger.info("ğŸ’¬ Using prompt: \(promptToUse.isEmpty ? "(default/empty)" : promptToUse.prefix(50).description + "...")")

            logger.info("ğŸš€ Sending request to LLM...")
            let processedText = try await provider.processText(
                text,
                prompt: promptToUse,
                model: config.postProcessModel
            )

            logger.info("âœ… LLM POST-PROCESSING COMPLETE")
            logger.info("  â†’ Input:  \(text.count) characters")
            logger.info("  â†’ Output: \(processedText.count) characters")
            logger.info("  â†’ Change: \(processedText.count - text.count) characters")
            logger.debug("  â†’ Output preview: \(processedText.prefix(100))...")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

            return processedText
        } catch {
            logger.error("âŒ LLM POST-PROCESSING FAILED")
            logger.error("  â†’ Error: \(error.localizedDescription)")
            logger.error("  â†’ Type: \(type(of: error))")
            if let llmError = error as? LLMError {
                logger.error("  â†’ LLM Error: \(llmError)")
            }
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            throw error
        }
    }

    /// Process text silently, returning original on failure
    /// - Parameters:
    ///   - text: The OCR text to process
    ///   - prompt: Optional custom prompt (uses default if nil)
    ///   - metadata: Optional OCR metadata context to help LLM understand the source
    /// - Returns: Processed text or original text on failure
    public func processSilently(_ text: String, prompt: String? = nil, metadata: String? = nil) async -> String {
        do {
            return try await process(text, prompt: prompt, metadata: metadata)
        } catch {
            logger.warning("âš ï¸ Post-processing failed silently, returning original text")
            return text
        }
    }

    /// Update configuration
    public func updateConfiguration(_ newConfig: LLMConfiguration) {
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ”„ UPDATING LLM POST-PROCESSOR CONFIGURATION")
        logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info("ğŸ“‹ Old config: Provider=\(self.config.postProcessProvider.rawValue), Model=\(self.config.postProcessModel)")
        logger.info("ğŸ“‹ New config: Provider=\(newConfig.postProcessProvider.rawValue), Model=\(newConfig.postProcessModel)")

        self.config = newConfig

        // Recreate provider with new configuration
        do {
            self.provider = try UnifiedLanguageModelProvider(
                providerType: newConfig.postProcessProvider,
                apiKey: newConfig.resolvePostProcessAPIKey(),
                endpoint: newConfig.postProcessCustomEndpoint,
                modelName: newConfig.postProcessModel
            )
            logger.info("âœ… LLM post-processor updated successfully")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        } catch {
            logger.error("âŒ FAILED TO UPDATE POST-PROCESSOR")
            logger.error("  â†’ Error: \(error.localizedDescription)")
            logger.error("  â†’ Type: \(type(of: error))")
            logger.info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            self.provider = nil
        }
    }
}
